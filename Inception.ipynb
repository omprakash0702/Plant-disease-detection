{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2deea0d-0f67-4f41-815c-2f12631d6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265a1db7-98cd-4b59-b464-bd9fd37f266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images and labels from folder\n",
    "def load_images_and_labels(folder, target_size=(100, 100)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subfolder in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        label = subfolder\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            image_path = os.path.join(subfolder_path, filename)\n",
    "            try:\n",
    "                img = image.load_img(image_path, target_size=target_size)\n",
    "                img = image.img_to_array(img)\n",
    "                img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image: {image_path} - {str(e)}\")\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46b5b68-8d2e-494b-bc66-1b0dc9e5fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "train_folder = 'C:/Users/KIIT/Downloads/Cashew/Cashew/train'\n",
    "test_folder ='C:/Users/KIIT/Downloads/Cashew/Cashew/test'\n",
    "val_folder ='C:/Users/KIIT/Downloads/Cashew/Cashew/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f35fc1-e306-4a49-8c70-a62bea565c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels for training, testing, and validation\n",
    "X_train, y_train = load_images_and_labels(train_folder)\n",
    "X_test, y_test = load_images_and_labels(test_folder)\n",
    "X_val, y_val = load_images_and_labels(val_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6810651-a8b9-4bfc-9df6-28a8b65a5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels to integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e005787-15fa-4816-a8ff-5a1b8d48501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load InceptionV3 model pre-trained on ImageNet without the top classification layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c0db76-b51f-4a34-ab7e-e0a47a005740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c0bffd-18e1-4e56-a254-ef8b49a3b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871f2931-656e-41cd-a398-2594898d983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a logistic layer for the number of classes\n",
    "predictions = Dense(len(set(y_train)), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5abc09d7-b36f-4dd9-a6d3-66f4486c5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592a1391-99c3-4dd4-b0eb-da7e7f54a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9d420fd-2b31-423a-b324-4d1b6490df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 1s/step - accuracy: 0.5847 - loss: 0.9868 - val_accuracy: 0.8842 - val_loss: 0.3288\n",
      "Epoch 2/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 976ms/step - accuracy: 0.8890 - loss: 0.3305 - val_accuracy: 0.9066 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 947ms/step - accuracy: 0.9308 - loss: 0.1936 - val_accuracy: 0.9128 - val_loss: 0.2694\n",
      "Epoch 4/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.9513 - loss: 0.1617 - val_accuracy: 0.9290 - val_loss: 0.2781\n",
      "Epoch 5/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 950ms/step - accuracy: 0.9602 - loss: 0.1241 - val_accuracy: 0.9340 - val_loss: 0.2600\n",
      "Epoch 6/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 1s/step - accuracy: 0.9788 - loss: 0.0772 - val_accuracy: 0.9240 - val_loss: 0.2993\n",
      "Epoch 7/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.9791 - loss: 0.0770 - val_accuracy: 0.9315 - val_loss: 0.3396\n",
      "Epoch 8/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 936ms/step - accuracy: 0.9887 - loss: 0.0403 - val_accuracy: 0.9153 - val_loss: 0.3845\n",
      "Epoch 9/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 932ms/step - accuracy: 0.9718 - loss: 0.0954 - val_accuracy: 0.9240 - val_loss: 0.2915\n",
      "Epoch 10/10\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 925ms/step - accuracy: 0.9839 - loss: 0.0485 - val_accuracy: 0.9203 - val_loss: 0.3078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fc133347d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d417339-b99a-4a14-a0b5-8ec6bbf15d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 170ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "train_pred = model.predict(X_train)\n",
    "val_pred = model.predict(X_val)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "223125c7-4bb0-4454-a33c-d4f47d0f5302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 143ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict probability estimates\n",
    "train_pred_proba = model.predict(X_train)\n",
    "val_pred_proba = model.predict(X_val)\n",
    "test_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Get probability estimates for the positive class\n",
    "train_pos_proba = train_pred_proba[:, 1]\n",
    "val_pos_proba = val_pred_proba[:, 1]\n",
    "test_pos_proba = test_pred_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5c1dfc1-d012-4f61-b036-fbf2a5e7a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation Metrics \n",
    "train_accuracy = accuracy_score(y_train, np.argmax(train_pred, axis=1))\n",
    "val_accuracy = accuracy_score(y_val, np.argmax(val_pred, axis=1))\n",
    "test_accuracy = accuracy_score(y_test, np.argmax(test_pred, axis=1))\n",
    "\n",
    "train_precision = precision_score(y_train, np.argmax(train_pred, axis=1), average='weighted')\n",
    "val_precision = precision_score(y_val, np.argmax(val_pred, axis=1), average='weighted')\n",
    "test_precision = precision_score(y_test, np.argmax(test_pred, axis=1), average='weighted')\n",
    "\n",
    "train_recall = recall_score(y_train, np.argmax(train_pred, axis=1), average='weighted')\n",
    "val_recall = recall_score(y_val, np.argmax(val_pred, axis=1), average='weighted')\n",
    "test_recall = recall_score(y_test, np.argmax(test_pred, axis=1), average='weighted')\n",
    "\n",
    "train_f1 = f1_score(y_train, np.argmax(train_pred, axis=1), average='weighted')\n",
    "val_f1 = f1_score(y_val, np.argmax(val_pred, axis=1), average='weighted')\n",
    "test_f1 = f1_score(y_test, np.argmax(test_pred, axis=1), average='weighted')\n",
    "\n",
    "train_roc_auc = roc_auc_score(y_train, train_pred, average='macro', multi_class='ovr')\n",
    "val_roc_auc = roc_auc_score(y_val, val_pred, average='macro', multi_class='ovr')\n",
    "test_roc_auc = roc_auc_score(y_test, test_pred, average='macro', multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8689ffa8-c541-4fdc-b841-971b5c3cdcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data Accuracy: 0.9982817869415808\n",
      "Train data Precision: 0.9982820750007694\n",
      "Train data Recall: 0.9982817869415808\n",
      "Train data F1 Score: 0.9982812977297294\n",
      "Train data ROC AUC Score: 0.9999908254366403\n",
      "\n",
      "Validation data Accuracy: 0.9202988792029888\n",
      "Validation data Precision: 0.9199862098752922\n",
      "Validation data Recall: 0.9202988792029888\n",
      "Validation data F1 Score: 0.9197179329591705\n",
      "Validation data ROC AUC Score: 0.9881941414191501\n",
      "\n",
      "Test data Accuracy: 0.94375\n",
      "Test data Precision: 0.9435801096107835\n",
      "Test data Recall: 0.94375\n",
      "Test data F1 Score: 0.9436153410402258\n",
      "Test data ROC AUC Score: 0.9908833333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Train data Accuracy:\", train_accuracy)\n",
    "print(\"Train data Precision:\", train_precision)\n",
    "print(\"Train data Recall:\", train_recall)\n",
    "print(\"Train data F1 Score:\", train_f1)\n",
    "print(\"Train data ROC AUC Score:\", train_roc_auc)\n",
    "\n",
    "print(\"\\nValidation data Accuracy:\", val_accuracy)\n",
    "print(\"Validation data Precision:\", val_precision)\n",
    "print(\"Validation data Recall:\", val_recall)\n",
    "print(\"Validation data F1 Score:\", val_f1)\n",
    "print(\"Validation data ROC AUC Score:\", val_roc_auc)\n",
    "\n",
    "print(\"\\nTest data Accuracy:\", test_accuracy)\n",
    "print(\"Test data Precision:\", test_precision)\n",
    "print(\"Test data Recall:\", test_recall)\n",
    "print(\"Test data F1 Score:\", test_f1)\n",
    "print(\"Test data ROC AUC Score:\", test_roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf52064b-041d-4b64-a545-55f116171d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('model_inception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bc2ba72-b6b6-4a5c-96ec-4418dabe2e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\t\t\tTrain\t\tValidation\tTest\n",
      "Accuracy\t\t0.9983\t\t0.9203\t\t0.9437\n",
      "Precision\t\t0.9983\t\t0.9200\t\t0.9436\n",
      "Recall\t\t\t0.9983\t\t0.9203\t\t0.9437\n",
      "F1 Score\t\t0.9983\t\t0.9197\t\t0.9436\n",
      "ROC AUC Score\t\t1.0000\t\t0.9882\t\t0.9909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_prob):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "def print_metrics_table(train_metrics, val_metrics, test_metrics):\n",
    "    print(\"Metrics\\t\\t\\tTrain\\t\\tValidation\\tTest\")\n",
    "    print(\"Accuracy\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(train_metrics[0], val_metrics[0], test_metrics[0]))\n",
    "    print(\"Precision\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(train_metrics[1], val_metrics[1], test_metrics[1]))\n",
    "    print(\"Recall\\t\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(train_metrics[2], val_metrics[2], test_metrics[2]))\n",
    "    print(\"F1 Score\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(train_metrics[3], val_metrics[3], test_metrics[3]))\n",
    "    print(\"ROC AUC Score\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(train_metrics[4], val_metrics[4], test_metrics[4]))\n",
    "\n",
    "# Assuming train_metrics, val_metrics, and test_metrics are tuples/lists containing metrics in the order: (accuracy, precision, recall, f1_score, roc_auc_score)\n",
    "train_metrics = (train_accuracy, train_precision, train_recall, train_f1, train_roc_auc)\n",
    "val_metrics = (val_accuracy, val_precision, val_recall, val_f1, val_roc_auc)\n",
    "test_metrics = (test_accuracy, test_precision, test_recall, test_f1, test_roc_auc)\n",
    "\n",
    "print_metrics_table(train_metrics, val_metrics, test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fc533-271d-465d-bf45-17d6e0a2560a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
